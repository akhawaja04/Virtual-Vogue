{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q gdown\n!gdown --id 1pCazDPlbyaWqiupLS87zj80dNl65mfrp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:07:49.530203Z","iopub.execute_input":"2025-05-10T09:07:49.530456Z","iopub.status.idle":"2025-05-10T09:08:17.227906Z","shell.execute_reply.started":"2025-05-10T09:07:49.530437Z","shell.execute_reply":"2025-05-10T09:08:17.227192Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1pCazDPlbyaWqiupLS87zj80dNl65mfrp\nFrom (redirected): https://drive.google.com/uc?id=1pCazDPlbyaWqiupLS87zj80dNl65mfrp&confirm=t&uuid=371b0a05-0ca5-4f28-a0a3-e5996f4feb50\nTo: /kaggle/working/Virtual_Vogue.zip\n100%|███████████████████████████████████████| 1.90G/1.90G [00:18<00:00, 104MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!unzip Virtual_Vogue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:08:17.229473Z","iopub.execute_input":"2025-05-10T09:08:17.229745Z","iopub.status.idle":"2025-05-10T09:08:36.540093Z","shell.execute_reply.started":"2025-05-10T09:08:17.229725Z","shell.execute_reply":"2025-05-10T09:08:36.539450Z"}},"outputs":[{"name":"stdout","text":"Archive:  Virtual_Vogue.zip\n   creating: content/Virtual_Vogue/\n  inflating: content/Virtual_Vogue/app.py  \n   creating: content/Virtual_Vogue/preprocess/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/run_parsing.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/datasets/\n extracting: content/Virtual_Vogue/preprocess/humanparsing/datasets/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/datasets/simple_extractor_dataset.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/datasets/datasets.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/datasets/target_generation.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/demo/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/demo/demo.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/demo/predictor.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/demo/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/GETTING_STARTED.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/PascalVOC-Detection/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Detectron1-Comparisons/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Detectron1-Comparisons/faster_rcnn_R_50_FPN_noaug_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Detectron1-Comparisons/mask_rcnn_R_50_FPN_noaug_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Detectron1-Comparisons/keypoint_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Detectron1-Comparisons/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/my_Base-RCNN-FPN.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Cityscapes/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Cityscapes/mask_rcnn_R_50_FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Base-RCNN-C4.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/rpn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/cascade_mask_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/keypoint_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/semantic_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/cascade_mask_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_C4_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/panoptic_fpn_R_50_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/retinanet_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/fast_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/keypoint_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/panoptic_fpn_R_50_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/keypoint_rcnn_R_50_FPN_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/rpn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_C4_GCV_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/fast_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_C4_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_C4_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_DC5_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/semantic_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/semantic_R_50_FPN_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/quick_schedules/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Base-RCNN-DilatedC5.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/LVIS-InstanceSegmentation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/LVIS-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/parsing_finetune_cihp.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/semantic_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/scratch_mask_rcnn_R_50_FPN_9x_syncbn.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/mask_rcnn_R_50_FPN_3x_syncbn.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/parsing_inference.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/scratch_mask_rcnn_R_50_FPN_3x_gn.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/demo.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/scratch_mask_rcnn_R_50_FPN_9x_gn.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv_parsing.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Misc/mask_rcnn_R_50_FPN_3x_gn.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/Base-Keypoint-RCNN-FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Base-RetinaNet.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/rpn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/rpn_R_50_C4_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-Detection/faster_rcnn_R_101_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/Base-RCNN-FPN.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-PanopticSegmentation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/configs/COCO-PanopticSegmentation/Base-Panoptic-FPN.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/solver/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/solver/lr_scheduler.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/solver/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/solver/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/rotated_coco_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/coco_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/panoptic_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/pascal_voc_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/sem_seg_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/testing.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/lvis_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/evaluator.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/evaluation/cityscapes_evaluation.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/instances.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/image_list.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/masks.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/keypoints.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/rotated_boxes.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/structures/boxes.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/mask_ops.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/wrappers.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/roi_align.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/blocks.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/nms.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/vision.cpp  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/box_iou_rotated/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_utils.h  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/nms_rotated/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlign/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlign/ROIAlign.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlignRotated/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/deformable/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/deformable/deform_conv.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/cuda_version.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/csrc/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/deform_conv.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/shape_spec.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/roi_align_rotated.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/rotated_boxes.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/layers/batch_norm.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/model_zoo/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/model_zoo/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/model_zoo/model_zoo.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/checkpoint/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/checkpoint/detection_checkpoint.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/checkpoint/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/checkpoint/c2_model_loading.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/checkpoint/catalog.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/defaults.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/hooks.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/train_loop.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/engine/launch.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/caffe2_inference.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/api.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/caffe2_export.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/shared.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/caffe2_modeling.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/patcher.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/export/c10.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/samplers/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/samplers/distributed_sampler.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/samplers/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/samplers/grouped_batch_sampler.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/register_coco.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/builtin.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/builtin_meta.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/cityscapes.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/lvis.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/coco.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/pascal_voc.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/lvis_v0_5_categories.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/datasets/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/detection_utils.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/catalog.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/dataset_mapper.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/common.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/transforms/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/transforms/transform_gen.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/transforms/transform.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/data/transforms/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/events.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/colormap.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/serialize.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/memory.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/analysis.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/collect_env.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/comm.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/env.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/video_visualizer.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/registry.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/logger.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/visualizer.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/utils/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/semantic_seg.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/panoptic_fpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/rcnn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/meta_arch/retinanet.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/keypoint_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/box_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/rotated_fast_rcnn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/mask_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/roi_heads.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/roi_heads/cascade_rcnn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/proposal_utils.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/rpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/proposal_generator/rrpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/matcher.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/test_time_augmentation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/poolers.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/postprocessing.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/anchor_generator.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/sampling.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/box_regression.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/fpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/backbone.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/modeling/backbone/resnet.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/config/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/config/defaults.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/config/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/config/compat.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/detectron2/config/config.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/setup.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/setup.cfg  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/config.yml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/questions-help-support.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/feature-request.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/bugs.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE/unexpected-problems-bugs.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/pull_request_template.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/ISSUE_TEMPLATE.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/CODE_OF_CONDUCT.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/Detectron2-Logo-Horz.svg  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.github/CONTRIBUTING.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.clang-format  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.flake8  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_visualizer.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_config.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_checkpoint.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_model_analysis.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_export_caffe2.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/test_imagelist.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/test_rotated_boxes.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/test_boxes.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/structures/test_instances.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/test_mask_ops.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/test_nms_rotated.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/test_roi_align_rotated.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/layers/test_roi_align.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/test_model_zoo.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/test_rotation_transform.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/test_coco.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/test_transforms.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/test_sampler.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/data/test_detection_utils.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_anchor_generator.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_roi_heads.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_box2box_transform.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_fast_rcnn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_rpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_model_e2e.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/modeling/test_roi_pooler.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tests/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/index.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/conf.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/index.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/benchmarks.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/contributing.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/compatibility.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/notes/changelog.md  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/.gitignore  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/index.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/utils.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/model_zoo.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/structures.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/checkpoint.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/engine.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/evaluation.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/modeling.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/config.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/layers.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/data.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/solver.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/modules/export.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/Makefile  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/index.rst  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/builtin_datasets.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/getting_started.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/deployment.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/datasets.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/configs.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/data_loading.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/write-models.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/extend.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/training.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/evaluation.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/install.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/models.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docs/tutorials/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.gitignore  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docker/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docker/Dockerfile  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docker/docker-compose.yml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docker/Dockerfile-circleci  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/docker/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/parse_results.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/run_instant_tests.sh  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/gen_wheel_index.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/pkg_helpers.bash  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/build_all_wheels.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/packaging/build_wheel.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/run_inference_tests.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/linter.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/dev/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/MODEL_ZOO.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/trident_backbone.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/trident_rpn.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/config.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/trident_conv.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/tridentnet/trident_rcnn.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/configs/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/configs/tridentnet_fast_R_50_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/configs/tridentnet_fast_R_50_C4_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/configs/tridentnet_fast_R_101_C4_3x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/configs/Base-TridentNet-Fast-C4.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TridentNet/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/SemanticSegmentation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/SemanticSegmentation/Base-PointRend-Semantic-FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/SemanticSegmentation/pointrend_semantic_R_50_FPN_1x_coco.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/SemanticSegmentation/pointrend_semantic_R_101_FPN_1x_cityscapes.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_parsing.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_parsing.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/Base-PointRend-RCNN-FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_1x_coco.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_1x_cityscapes.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/semantic_seg.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/color_augmentation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/roi_heads.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/point_features.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/dataset_mapper.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/config.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/coarse_mask_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/point_rend/point_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/run.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/finetune_net.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/logs/\n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/logs/hadoop.kylin.libdfs.log  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/PointRend/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/configs/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/configs/Base-TensorMask.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/configs/tensormask_R_50_FPN_1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/configs/tensormask_R_50_FPN_6x.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/swap_align2nat.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/csrc/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/csrc/vision.cpp  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/csrc/SwapAlign2Nat/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/csrc/SwapAlign2Nat/SwapAlign2Nat_cuda.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/layers/csrc/SwapAlign2Nat/SwapAlign2Nat.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/arch.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tensormask/config.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/setup.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tests/\n extracting: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tests/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/tests/test_swap_align2nat.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/TensorMask/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/\n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_DL_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_DL_WC1_s1x.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/evolution/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/evolution/Base-RCNN-FPN-MC.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/evolution/faster_rcnn_R_50_FPN_1x_MC.yaml  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_TTA_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_DL_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_WC1_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/quick_schedules/densepose_rcnn_R_50_FPN_WC2_instant_test.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_DL_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_s1x_legacy.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_101_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/Base-DensePose-RCNN-FPN.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_DL_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_s1x_legacy.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_s1x.yaml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/query_db.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/tests/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/tests/test_structures.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/tests/test_setup.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/tests/common.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/tests/test_model_e2e.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/dev/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/dev/run_instant_tests.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/dev/run_inference_tests.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/dev/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/apply_net.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/densepose_coco_evaluation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/vis/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/vis/densepose.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/vis/base.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/vis/bounding_box.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/vis/extractor.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/roi_head.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/evaluator.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/config.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/datasets/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/datasets/builtin.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/datasets/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/datasets/coco.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/structures.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/build.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/data/dataset_mapper.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/utils/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/utils/dbhelper.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/utils/transform.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/utils/logger.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/modeling/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/modeling/test_time_augmentation.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/densepose/densepose_head.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/doc/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/doc/GETTING_STARTED.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/doc/TOOL_QUERY_DB.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/doc/TOOL_APPLY_NET.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/doc/MODEL_ZOO.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/DensePose/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/projects/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/INSTALL.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.circleci/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/.circleci/config.yml  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/LICENSE  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/convert-torchvision-to-d2.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/inference.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/run.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/benchmark.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/deploy/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/deploy/caffe2_mask_rcnn.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/deploy/caffe2_converter.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/deploy/torchscript_traced_mask_rcnn.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/deploy/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/visualize_data.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/finetune_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/analyze_model.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/visualize_json_results.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/plain_train_net.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/tools/README.md  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/detectron2/README.md  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/global_local_parsing/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/global_local_parsing/global_local_datasets.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/global_local_parsing/global_local_train.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/global_local_parsing/make_id_list.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/global_local_parsing/global_local_evaluate.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/scripts/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/scripts/make_crop.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/scripts/make_coco_style_annotation.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/scripts/parsing_fusion.sh  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/logits_fusion.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/make_crop_and_mask_w_mask_nms.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/coco_style_annotation_creator/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/coco_style_annotation_creator/test_human2coco_format.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/coco_style_annotation_creator/pycococreatortools.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/mhp_extension/coco_style_annotation_creator/human_to_coco.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/parsing_api.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/modules/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/deeplab.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/functions.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/misc.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/dense.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/residual.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/bn.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/inplace_abn_cpu.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/inplace_abn.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/inplace_abn.cpp  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/checks.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/inplace_abn_cuda_half.cu  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/inplace_abn_cuda.cu  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/utils/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/utils/checks.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/utils/common.h  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/modules/src/utils/cuda.cuh  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/networks/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/AugmentCE2P.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/__init__.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/networks/context_encoding/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/context_encoding/psp.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/context_encoding/aspp.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/context_encoding/ocnet.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/networks/backbone/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/backbone/mobilenetv2.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/backbone/resnext.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/networks/backbone/resnet.py  \n   creating: content/Virtual_Vogue/preprocess/humanparsing/utils/\n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/transforms.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/criterion.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/lovasz_softmax.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/miou.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/consistency_loss.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/soft_dice_loss.py  \n extracting: content/Virtual_Vogue/preprocess/humanparsing/utils/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/schp.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/encoding.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/kl_loss.py  \n  inflating: content/Virtual_Vogue/preprocess/humanparsing/utils/warmup_scheduler.py  \n   creating: content/Virtual_Vogue/preprocess/openpose/\n   creating: content/Virtual_Vogue/preprocess/openpose/annotator/\n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/util.py  \n   creating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/\n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/util.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/face.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/__init__.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/body.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/model.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/LICENSE  \n  inflating: content/Virtual_Vogue/preprocess/openpose/annotator/openpose/hand.py  \n  inflating: content/Virtual_Vogue/preprocess/openpose/run_openpose.py  \n  inflating: content/Virtual_Vogue/.gitattributes  \n   creating: content/Virtual_Vogue/ip_adapter/\n  inflating: content/Virtual_Vogue/ip_adapter/resampler.py  \n  inflating: content/Virtual_Vogue/ip_adapter/ip_adapter.py  \n  inflating: content/Virtual_Vogue/ip_adapter/utils.py  \n  inflating: content/Virtual_Vogue/ip_adapter/test_resampler.py  \n  inflating: content/Virtual_Vogue/ip_adapter/__init__.py  \n  inflating: content/Virtual_Vogue/ip_adapter/attention_processor.py  \n   creating: content/Virtual_Vogue/configs/\n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_DL_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_DL_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_WC2M_s1x.yaml  \n   creating: content/Virtual_Vogue/configs/evolution/\n  inflating: content/Virtual_Vogue/configs/evolution/densepose_R_50_FPN_DL_WC1M_3x_Atop10P_CA.yaml  \n  inflating: content/Virtual_Vogue/configs/evolution/densepose_R_50_FPN_DL_WC1M_3x_Atop10P_CA_B_finesegm.yaml  \n  inflating: content/Virtual_Vogue/configs/evolution/densepose_R_50_FPN_DL_WC1M_3x_Atop10P_CA_B_uniform.yaml  \n  inflating: content/Virtual_Vogue/configs/evolution/densepose_R_50_FPN_DL_WC1M_3x_Atop10P_CA_B_coarsesegm.yaml  \n  inflating: content/Virtual_Vogue/configs/evolution/Base-RCNN-FPN-Atop10P_CA.yaml  \n  inflating: content/Virtual_Vogue/configs/evolution/densepose_R_50_FPN_DL_WC1M_3x_Atop10P_CA_B_uv.yaml  \n   creating: content/Virtual_Vogue/configs/quick_schedules/\n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_TTA_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_DL_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_inference_acc_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_HRFPN_HRNet_w32_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_training_acc_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_WC1_instant_test.yaml  \n   creating: content/Virtual_Vogue/configs/quick_schedules/cse/\n  inflating: content/Virtual_Vogue/configs/quick_schedules/cse/densepose_rcnn_R_50_FPN_soft_animals_finetune_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/cse/densepose_rcnn_R_50_FPN_DL_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/quick_schedules/densepose_rcnn_R_50_FPN_WC2_instant_test.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_DL_WC1_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_WC2M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_DL_WC2M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_WC1M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_s1x_legacy.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_WC1M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_DL_WC1M_s1x.yaml  \n   creating: content/Virtual_Vogue/configs/cse/\n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_I0_finetune_16k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_I0_finetune_i2m_16k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_I0_finetune_m2m_16k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/Base-DensePose-RCNN-FPN-Human.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_101_FPN_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_101_FPN_soft_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_DL_soft_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_chimps_finetune_4k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_finetune_16k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_101_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/Base-DensePose-RCNN-FPN.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_finetune_maskonly_24k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_CA_finetune_4k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_CA_finetune_16k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_animals_finetune_4k.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_101_FPN_DL_soft_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_soft_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/cse/densepose_rcnn_R_50_FPN_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_101_FPN_DL_WC2M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_DL_WC1M_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/Base-DensePose-RCNN-FPN.yaml  \n   creating: content/Virtual_Vogue/configs/HRNet/\n  inflating: content/Virtual_Vogue/configs/HRNet/densepose_rcnn_HRFPN_HRNet_w40_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/HRNet/densepose_rcnn_HRFPN_HRNet_w48_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/HRNet/densepose_rcnn_HRFPN_HRNet_w32_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_DL_WC2_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_s1x_legacy.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_DL_s1x.yaml  \n  inflating: content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_s1x.yaml  \n   creating: content/Virtual_Vogue/detectron2/\n   creating: content/Virtual_Vogue/detectron2/tracking/\n  inflating: content/Virtual_Vogue/detectron2/tracking/utils.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/iou_weighted_hungarian_bbox_iou_tracker.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/bbox_iou_tracker.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/vanilla_hungarian_bbox_iou_tracker.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/hungarian_tracker.py  \n  inflating: content/Virtual_Vogue/detectron2/tracking/base_tracker.py  \n   creating: content/Virtual_Vogue/detectron2/solver/\n  inflating: content/Virtual_Vogue/detectron2/solver/lr_scheduler.py  \n  inflating: content/Virtual_Vogue/detectron2/solver/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/solver/build.py  \n  inflating: content/Virtual_Vogue/detectron2/__init__.py  \n   creating: content/Virtual_Vogue/detectron2/evaluation/\n  inflating: content/Virtual_Vogue/detectron2/evaluation/rotated_coco_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/fast_eval_api.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/coco_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/panoptic_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/pascal_voc_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/sem_seg_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/testing.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/lvis_evaluation.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/evaluator.py  \n  inflating: content/Virtual_Vogue/detectron2/evaluation/cityscapes_evaluation.py  \n   creating: content/Virtual_Vogue/detectron2/structures/\n  inflating: content/Virtual_Vogue/detectron2/structures/instances.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/image_list.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/masks.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/keypoints.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/rotated_boxes.py  \n  inflating: content/Virtual_Vogue/detectron2/structures/boxes.py  \n   creating: content/Virtual_Vogue/detectron2/layers/\n  inflating: content/Virtual_Vogue/detectron2/layers/aspp.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/mask_ops.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/wrappers.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/roi_align.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/blocks.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/nms.py  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/vision.cpp  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/box_iou_rotated/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated.h  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_utils.h  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/nms_rotated/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/nms_rotated/nms_rotated.h  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/ROIAlignRotated/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/deformable/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/deformable/deform_conv_cuda.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/deformable/deform_conv.h  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/cuda_version.cu  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/README.md  \n   creating: content/Virtual_Vogue/detectron2/layers/csrc/cocoeval/\n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/cocoeval/cocoeval.cpp  \n  inflating: content/Virtual_Vogue/detectron2/layers/csrc/cocoeval/cocoeval.h  \n  inflating: content/Virtual_Vogue/detectron2/layers/losses.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/deform_conv.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/shape_spec.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/roi_align_rotated.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/rotated_boxes.py  \n  inflating: content/Virtual_Vogue/detectron2/layers/batch_norm.py  \n   creating: content/Virtual_Vogue/detectron2/model_zoo/\n  inflating: content/Virtual_Vogue/detectron2/model_zoo/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/model_zoo/model_zoo.py  \n   creating: content/Virtual_Vogue/detectron2/checkpoint/\n  inflating: content/Virtual_Vogue/detectron2/checkpoint/detection_checkpoint.py  \n  inflating: content/Virtual_Vogue/detectron2/checkpoint/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/checkpoint/c2_model_loading.py  \n  inflating: content/Virtual_Vogue/detectron2/checkpoint/catalog.py  \n   creating: content/Virtual_Vogue/detectron2/engine/\n  inflating: content/Virtual_Vogue/detectron2/engine/defaults.py  \n  inflating: content/Virtual_Vogue/detectron2/engine/hooks.py  \n  inflating: content/Virtual_Vogue/detectron2/engine/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/engine/train_loop.py  \n  inflating: content/Virtual_Vogue/detectron2/engine/launch.py  \n   creating: content/Virtual_Vogue/detectron2/projects/\n  inflating: content/Virtual_Vogue/detectron2/projects/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/projects/README.md  \n   creating: content/Virtual_Vogue/detectron2/export/\n  inflating: content/Virtual_Vogue/detectron2/export/torchscript.py  \n  inflating: content/Virtual_Vogue/detectron2/export/torchscript_patch.py  \n  inflating: content/Virtual_Vogue/detectron2/export/caffe2_inference.py  \n  inflating: content/Virtual_Vogue/detectron2/export/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/export/flatten.py  \n  inflating: content/Virtual_Vogue/detectron2/export/api.py  \n  inflating: content/Virtual_Vogue/detectron2/export/caffe2_patch.py  \n  inflating: content/Virtual_Vogue/detectron2/export/caffe2_export.py  \n  inflating: content/Virtual_Vogue/detectron2/export/shared.py  \n  inflating: content/Virtual_Vogue/detectron2/export/caffe2_modeling.py  \n  inflating: content/Virtual_Vogue/detectron2/export/README.md  \n  inflating: content/Virtual_Vogue/detectron2/export/c10.py  \n  inflating: content/Virtual_Vogue/detectron2/_C.cpython-39-x86_64-linux-gnu.so  \n   creating: content/Virtual_Vogue/detectron2/data/\n   creating: content/Virtual_Vogue/detectron2/data/samplers/\n  inflating: content/Virtual_Vogue/detectron2/data/samplers/distributed_sampler.py  \n  inflating: content/Virtual_Vogue/detectron2/data/samplers/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/data/samplers/grouped_batch_sampler.py  \n  inflating: content/Virtual_Vogue/detectron2/data/benchmark.py  \n  inflating: content/Virtual_Vogue/detectron2/data/__init__.py  \n   creating: content/Virtual_Vogue/detectron2/data/datasets/\n  inflating: content/Virtual_Vogue/detectron2/data/datasets/register_coco.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/builtin.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/builtin_meta.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/lvis_v1_categories.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/cityscapes.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/lvis.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/lvis_v1_category_image_count.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/cityscapes_panoptic.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/coco_panoptic.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/coco.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/pascal_voc.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/lvis_v0_5_categories.py  \n  inflating: content/Virtual_Vogue/detectron2/data/datasets/README.md  \n  inflating: content/Virtual_Vogue/detectron2/data/build.py  \n  inflating: content/Virtual_Vogue/detectron2/data/detection_utils.py  \n  inflating: content/Virtual_Vogue/detectron2/data/catalog.py  \n  inflating: content/Virtual_Vogue/detectron2/data/dataset_mapper.py  \n  inflating: content/Virtual_Vogue/detectron2/data/common.py  \n   creating: content/Virtual_Vogue/detectron2/data/transforms/\n  inflating: content/Virtual_Vogue/detectron2/data/transforms/transform.py  \n  inflating: content/Virtual_Vogue/detectron2/data/transforms/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/data/transforms/augmentation_impl.py  \n  inflating: content/Virtual_Vogue/detectron2/data/transforms/augmentation.py  \n   creating: content/Virtual_Vogue/detectron2/utils/\n  inflating: content/Virtual_Vogue/detectron2/utils/events.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/file_io.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/colormap.py  \n extracting: content/Virtual_Vogue/detectron2/utils/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/serialize.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/memory.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/analysis.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/testing.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/collect_env.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/comm.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/env.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/video_visualizer.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/develop.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/registry.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/tracing.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/logger.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/visualizer.py  \n  inflating: content/Virtual_Vogue/detectron2/utils/README.md  \n   creating: content/Virtual_Vogue/detectron2/modeling/\n   creating: content/Virtual_Vogue/detectron2/modeling/meta_arch/\n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/semantic_seg.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/panoptic_fpn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/rcnn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/build.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/fcos.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/retinanet.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/meta_arch/dense_detector.py  \n   creating: content/Virtual_Vogue/detectron2/modeling/roi_heads/\n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/keypoint_head.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/box_head.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/rotated_fast_rcnn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/mask_head.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/roi_heads.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/fast_rcnn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/roi_heads/cascade_rcnn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/__init__.py  \n   creating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/\n  inflating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/proposal_utils.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/rpn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/build.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/proposal_generator/rrpn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/matcher.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/test_time_augmentation.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/poolers.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/postprocessing.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/anchor_generator.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/mmdet_wrapper.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/sampling.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/box_regression.py  \n   creating: content/Virtual_Vogue/detectron2/modeling/backbone/\n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/swin.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/utils.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/mvit.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/fpn.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/backbone.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/regnet.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/build.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/resnet.py  \n  inflating: content/Virtual_Vogue/detectron2/modeling/backbone/vit.py  \n   creating: content/Virtual_Vogue/detectron2/config/\n  inflating: content/Virtual_Vogue/detectron2/config/lazy.py  \n  inflating: content/Virtual_Vogue/detectron2/config/defaults.py  \n  inflating: content/Virtual_Vogue/detectron2/config/__init__.py  \n  inflating: content/Virtual_Vogue/detectron2/config/compat.py  \n  inflating: content/Virtual_Vogue/detectron2/config/config.py  \n  inflating: content/Virtual_Vogue/detectron2/config/instantiate.py  \n  inflating: content/Virtual_Vogue/vitonhd_test_tagged.json  \n   creating: content/Virtual_Vogue/util/\n  inflating: content/Virtual_Vogue/util/image.py  \n  inflating: content/Virtual_Vogue/util/pipeline.py  \n  inflating: content/Virtual_Vogue/util/common.py  \n   creating: content/Virtual_Vogue/ckpt/\n   creating: content/Virtual_Vogue/ckpt/humanparsing/\n  inflating: content/Virtual_Vogue/ckpt/humanparsing/parsing_lip.onnx  \n  inflating: content/Virtual_Vogue/ckpt/humanparsing/parsing_atr.onnx  \n   creating: content/Virtual_Vogue/ckpt/openpose/\n   creating: content/Virtual_Vogue/ckpt/openpose/ckpts/\n  inflating: content/Virtual_Vogue/ckpt/openpose/ckpts/body_pose_model.pth  \n  inflating: content/Virtual_Vogue/ckpt/openpose/.DS_Store  \n   creating: content/Virtual_Vogue/ckpt/densepose/\n  inflating: content/Virtual_Vogue/ckpt/densepose/model_final_162be9.pkl  \n  inflating: content/Virtual_Vogue/inference.sh  \n  inflating: content/Virtual_Vogue/requirements.txt  \n  inflating: content/Virtual_Vogue/inference.py  \n   creating: content/Virtual_Vogue/.git/\n   creating: content/Virtual_Vogue/.git/lfs/\n   creating: content/Virtual_Vogue/.git/lfs/incomplete/\n   creating: content/Virtual_Vogue/.git/lfs/objects/\n   creating: content/Virtual_Vogue/.git/lfs/objects/25/\n   creating: content/Virtual_Vogue/.git/lfs/objects/25/a9/\n  inflating: content/Virtual_Vogue/.git/lfs/objects/25/a9/25a948c16078b0f08e236bda51a385d855ef4c153598947c28c0d47ed94bb746  \n   creating: content/Virtual_Vogue/.git/lfs/objects/04/\n   creating: content/Virtual_Vogue/.git/lfs/objects/04/c7/\n  inflating: content/Virtual_Vogue/.git/lfs/objects/04/c7/04c7d1d070d0e0ae943d86b18cb5aaaea9e278d97462e9cfb270cbbe4cd977f4  \n   creating: content/Virtual_Vogue/.git/lfs/objects/e9/\n   creating: content/Virtual_Vogue/.git/lfs/objects/e9/53/\n  inflating: content/Virtual_Vogue/.git/lfs/objects/e9/53/e953475b1378e1d0566f8ad8de20077ce8610ae23fb2b5f8bfe57104aca8e911  \n   creating: content/Virtual_Vogue/.git/lfs/objects/84/\n   creating: content/Virtual_Vogue/.git/lfs/objects/84/36/\n  inflating: content/Virtual_Vogue/.git/lfs/objects/84/36/8436e1dae96e2601c373d1ace29c8f0978b16357d9038c17a8ba756cca376dbc  \n   creating: content/Virtual_Vogue/.git/lfs/objects/b8/\n   creating: content/Virtual_Vogue/.git/lfs/objects/b8/a7/\n  inflating: content/Virtual_Vogue/.git/lfs/objects/b8/a7/b8a7382001b16e453bad95ca9dbc68ae8f2b839b304cf90eaf5c27fbdb4dae91  \n   creating: content/Virtual_Vogue/.git/lfs/tmp/\n   creating: content/Virtual_Vogue/.git/branches/\n  inflating: content/Virtual_Vogue/.git/description  \n   creating: content/Virtual_Vogue/.git/info/\n  inflating: content/Virtual_Vogue/.git/info/exclude  \n   creating: content/Virtual_Vogue/.git/hooks/\n  inflating: content/Virtual_Vogue/.git/hooks/fsmonitor-watchman.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/applypatch-msg.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/prepare-commit-msg.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-push  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-commit.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/post-commit  \n  inflating: content/Virtual_Vogue/.git/hooks/push-to-checkout.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-rebase.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/post-update.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-push.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/update.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/post-merge  \n  inflating: content/Virtual_Vogue/.git/hooks/commit-msg.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/post-checkout  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-receive.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-applypatch.sample  \n  inflating: content/Virtual_Vogue/.git/hooks/pre-merge-commit.sample  \n   creating: content/Virtual_Vogue/.git/logs/\n  inflating: content/Virtual_Vogue/.git/logs/HEAD  \n   creating: content/Virtual_Vogue/.git/logs/refs/\n   creating: content/Virtual_Vogue/.git/logs/refs/remotes/\n   creating: content/Virtual_Vogue/.git/logs/refs/remotes/origin/\n  inflating: content/Virtual_Vogue/.git/logs/refs/remotes/origin/HEAD  \n   creating: content/Virtual_Vogue/.git/logs/refs/heads/\n  inflating: content/Virtual_Vogue/.git/logs/refs/heads/main  \n  inflating: content/Virtual_Vogue/.git/packed-refs  \n extracting: content/Virtual_Vogue/.git/HEAD  \n  inflating: content/Virtual_Vogue/.git/index  \n   creating: content/Virtual_Vogue/.git/objects/\n   creating: content/Virtual_Vogue/.git/objects/info/\n   creating: content/Virtual_Vogue/.git/objects/pack/\n  inflating: content/Virtual_Vogue/.git/objects/pack/pack-12fd49e5d340f5f995734fb0280ba6108bd4eaa5.idx  \n  inflating: content/Virtual_Vogue/.git/objects/pack/pack-12fd49e5d340f5f995734fb0280ba6108bd4eaa5.pack  \n   creating: content/Virtual_Vogue/.git/refs/\n   creating: content/Virtual_Vogue/.git/refs/tags/\n   creating: content/Virtual_Vogue/.git/refs/remotes/\n   creating: content/Virtual_Vogue/.git/refs/remotes/origin/\n extracting: content/Virtual_Vogue/.git/refs/remotes/origin/HEAD  \n   creating: content/Virtual_Vogue/.git/refs/heads/\n extracting: content/Virtual_Vogue/.git/refs/heads/main  \n  inflating: content/Virtual_Vogue/.git/config  \n  inflating: content/Virtual_Vogue/utils_mask.py  \n  inflating: content/Virtual_Vogue/.gitignore  \n  inflating: content/Virtual_Vogue/app_VTON.py  \n   creating: content/Virtual_Vogue/assets/\n  inflating: content/Virtual_Vogue/assets/teaser2.png  \n  inflating: content/Virtual_Vogue/assets/teaser.png  \n   creating: content/Virtual_Vogue/example/\n   creating: content/Virtual_Vogue/example/human/\n  inflating: content/Virtual_Vogue/example/human/00055_00.jpg  \n  inflating: content/Virtual_Vogue/example/human/00121_00.jpg  \n  inflating: content/Virtual_Vogue/example/human/00034_00.jpg  \n  inflating: content/Virtual_Vogue/example/human/taylor-.jpg  \n  inflating: content/Virtual_Vogue/example/human/Jensen.jpeg  \n  inflating: content/Virtual_Vogue/example/human/sam1 (1).jpg  \n  inflating: content/Virtual_Vogue/example/human/01992_00.jpg  \n  inflating: content/Virtual_Vogue/example/human/will1 (1).jpg  \n  inflating: content/Virtual_Vogue/example/human/00035_00.jpg  \n   creating: content/Virtual_Vogue/example/cloth/\n  inflating: content/Virtual_Vogue/example/cloth/04743_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09263_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09256_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/14627_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09236_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09305_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09164_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09166_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09266_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09290_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/04469_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09133_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09176_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/10165_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/09163_00.jpg  \n  inflating: content/Virtual_Vogue/example/cloth/14673_00.jpg  \n   creating: content/Virtual_Vogue/src/\n  inflating: content/Virtual_Vogue/src/unet_hacked_garmnet.py  \n  inflating: content/Virtual_Vogue/src/attentionhacked_garmnet.py  \n  inflating: content/Virtual_Vogue/src/tryon_pipeline.py  \n  inflating: content/Virtual_Vogue/src/attentionhacked_tryon.py  \n  inflating: content/Virtual_Vogue/src/unet_hacked_tryon.py  \n  inflating: content/Virtual_Vogue/src/unet_block_hacked_garmnet.py  \n  inflating: content/Virtual_Vogue/src/transformerhacked_garmnet.py  \n  inflating: content/Virtual_Vogue/src/unet_block_hacked_tryon.py  \n  inflating: content/Virtual_Vogue/src/transformerhacked_tryon.py  \n  inflating: content/Virtual_Vogue/environment.yaml  \n  inflating: content/Virtual_Vogue/apply_net.py  \n  inflating: content/Virtual_Vogue/inference_dc.py  \n   creating: content/Virtual_Vogue/densepose/\n  inflating: content/Virtual_Vogue/densepose/__init__.py  \n   creating: content/Virtual_Vogue/densepose/evaluation/\n  inflating: content/Virtual_Vogue/densepose/evaluation/densepose_coco_evaluation.py  \n  inflating: content/Virtual_Vogue/densepose/evaluation/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/evaluation/mesh_alignment_evaluator.py  \n  inflating: content/Virtual_Vogue/densepose/evaluation/d2_evaluator_adapter.py  \n  inflating: content/Virtual_Vogue/densepose/evaluation/evaluator.py  \n  inflating: content/Virtual_Vogue/densepose/evaluation/tensor_storage.py  \n   creating: content/Virtual_Vogue/densepose/vis/\n  inflating: content/Virtual_Vogue/densepose/vis/base.py  \n extracting: content/Virtual_Vogue/densepose/vis/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/vis/densepose_data_points.py  \n  inflating: content/Virtual_Vogue/densepose/vis/bounding_box.py  \n  inflating: content/Virtual_Vogue/densepose/vis/extractor.py  \n  inflating: content/Virtual_Vogue/densepose/vis/densepose_outputs_iuv.py  \n  inflating: content/Virtual_Vogue/densepose/vis/densepose_outputs_vertex.py  \n  inflating: content/Virtual_Vogue/densepose/vis/densepose_results.py  \n  inflating: content/Virtual_Vogue/densepose/vis/densepose_results_textures.py  \n   creating: content/Virtual_Vogue/densepose/structures/\n  inflating: content/Virtual_Vogue/densepose/structures/cse.py  \n  inflating: content/Virtual_Vogue/densepose/structures/list.py  \n  inflating: content/Virtual_Vogue/densepose/structures/data_relative.py  \n  inflating: content/Virtual_Vogue/densepose/structures/cse_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/structures/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/structures/chart_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/structures/chart_result.py  \n  inflating: content/Virtual_Vogue/densepose/structures/transform_data.py  \n  inflating: content/Virtual_Vogue/densepose/structures/chart.py  \n  inflating: content/Virtual_Vogue/densepose/structures/mesh.py  \n   creating: content/Virtual_Vogue/densepose/converters/\n  inflating: content/Virtual_Vogue/densepose/converters/base.py  \n  inflating: content/Virtual_Vogue/densepose/converters/builtin.py  \n  inflating: content/Virtual_Vogue/densepose/converters/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/converters/to_mask.py  \n  inflating: content/Virtual_Vogue/densepose/converters/hflip.py  \n  inflating: content/Virtual_Vogue/densepose/converters/segm_to_mask.py  \n  inflating: content/Virtual_Vogue/densepose/converters/chart_output_to_chart_result.py  \n  inflating: content/Virtual_Vogue/densepose/converters/to_chart_result.py  \n  inflating: content/Virtual_Vogue/densepose/converters/chart_output_hflip.py  \n   creating: content/Virtual_Vogue/densepose/engine/\n  inflating: content/Virtual_Vogue/densepose/engine/trainer.py  \n  inflating: content/Virtual_Vogue/densepose/engine/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/config.py  \n   creating: content/Virtual_Vogue/densepose/data/\n   creating: content/Virtual_Vogue/densepose/data/transform/\n  inflating: content/Virtual_Vogue/densepose/data/transform/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/data/transform/image.py  \n  inflating: content/Virtual_Vogue/densepose/data/utils.py  \n   creating: content/Virtual_Vogue/densepose/data/samplers/\n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_confidence_based.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_cse_uniform.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_cse_confidence_based.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_cse_base.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_uniform.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/densepose_base.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/prediction_to_gt.py  \n  inflating: content/Virtual_Vogue/densepose/data/samplers/mask_from_densepose.py  \n  inflating: content/Virtual_Vogue/densepose/data/__init__.py  \n   creating: content/Virtual_Vogue/densepose/data/datasets/\n  inflating: content/Virtual_Vogue/densepose/data/datasets/chimpnsee.py  \n  inflating: content/Virtual_Vogue/densepose/data/datasets/builtin.py  \n  inflating: content/Virtual_Vogue/densepose/data/datasets/lvis.py  \n  inflating: content/Virtual_Vogue/densepose/data/datasets/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/data/datasets/coco.py  \n  inflating: content/Virtual_Vogue/densepose/data/datasets/dataset_type.py  \n  inflating: content/Virtual_Vogue/densepose/data/combined_loader.py  \n  inflating: content/Virtual_Vogue/densepose/data/image_list_dataset.py  \n  inflating: content/Virtual_Vogue/densepose/data/build.py  \n   creating: content/Virtual_Vogue/densepose/data/meshes/\n  inflating: content/Virtual_Vogue/densepose/data/meshes/builtin.py  \n  inflating: content/Virtual_Vogue/densepose/data/meshes/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/data/meshes/catalog.py  \n   creating: content/Virtual_Vogue/densepose/data/video/\n  inflating: content/Virtual_Vogue/densepose/data/video/frame_selector.py  \n  inflating: content/Virtual_Vogue/densepose/data/video/video_keyframe_dataset.py  \n  inflating: content/Virtual_Vogue/densepose/data/video/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/data/dataset_mapper.py  \n  inflating: content/Virtual_Vogue/densepose/data/inference_based_loader.py  \n   creating: content/Virtual_Vogue/densepose/utils/\n  inflating: content/Virtual_Vogue/densepose/utils/dbhelper.py  \n  inflating: content/Virtual_Vogue/densepose/utils/transform.py  \n extracting: content/Virtual_Vogue/densepose/utils/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/utils/logger.py  \n   creating: content/Virtual_Vogue/densepose/modeling/\n  inflating: content/Virtual_Vogue/densepose/modeling/filter.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/confidence.py  \n   creating: content/Virtual_Vogue/densepose/modeling/losses/\n  inflating: content/Virtual_Vogue/densepose/modeling/losses/mask_or_segm.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/segm.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/utils.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/soft_embed.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/cycle_shape2shape.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/cse.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/embed_utils.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/chart_with_confidences.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/registry.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/chart.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/embed.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/cycle_pix2shape.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/losses/mask.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/utils.py  \n   creating: content/Virtual_Vogue/densepose/modeling/predictors/\n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/chart_with_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/cse.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/cse_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/chart_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/cse_with_confidence.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/registry.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/predictors/chart.py  \n   creating: content/Virtual_Vogue/densepose/modeling/roi_heads/\n  inflating: content/Virtual_Vogue/densepose/modeling/roi_heads/deeplab.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/roi_heads/v1convx.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/roi_heads/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/roi_heads/roi_head.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/roi_heads/registry.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/densepose_checkpoint.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/inference.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/build.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/test_time_augmentation.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/hrnet.py  \n   creating: content/Virtual_Vogue/densepose/modeling/cse/\n  inflating: content/Virtual_Vogue/densepose/modeling/cse/utils.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/cse/__init__.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/cse/embedder.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/cse/vertex_direct_embedder.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/cse/vertex_feature_embedder.py  \n  inflating: content/Virtual_Vogue/densepose/modeling/hrfpn.py  \n  inflating: content/Virtual_Vogue/README.md  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:08:36.540967Z","iopub.execute_input":"2025-05-10T09:08:36.541189Z","iopub.status.idle":"2025-05-10T09:08:36.662326Z","shell.execute_reply.started":"2025-05-10T09:08:36.541157Z","shell.execute_reply":"2025-05-10T09:08:36.661485Z"}},"outputs":[{"name":"stdout","text":"content  Virtual_Vogue.zip\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!rm Virtual_Vogue.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:08:36.664130Z","iopub.execute_input":"2025-05-10T09:08:36.664344Z","iopub.status.idle":"2025-05-10T09:08:37.134606Z","shell.execute_reply.started":"2025-05-10T09:08:36.664325Z","shell.execute_reply":"2025-05-10T09:08:37.133894Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%cd content\n\n%cd Virtual_Vogue\n\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:08:37.135633Z","iopub.execute_input":"2025-05-10T09:08:37.136222Z","iopub.status.idle":"2025-05-10T09:08:37.259150Z","shell.execute_reply.started":"2025-05-10T09:08:37.136190Z","shell.execute_reply":"2025-05-10T09:08:37.258574Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/content\n/kaggle/working/content/Virtual_Vogue\napply_net.py  densepose\t\tinference.sh\t  util\napp.py\t      detectron2\tip_adapter\t  utils_mask.py\napp_VTON.py   environment.yaml\tpreprocess\t  vitonhd_test_tagged.json\nassets\t      example\t\tREADME.md\nckpt\t      inference_dc.py\trequirements.txt\nconfigs       inference.py\tsrc\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install -r requirements.txt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:08:37.260006Z","iopub.execute_input":"2025-05-10T09:08:37.260290Z","iopub.status.idle":"2025-05-10T09:11:47.905581Z","shell.execute_reply.started":"2025-05-10T09:08:37.260264Z","shell.execute_reply":"2025-05-10T09:11:47.904670Z"}},"outputs":[{"name":"stdout","text":"Collecting numpy==1.24.4 (from -r requirements.txt (line 1))\n  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting scipy==1.10.1 (from -r requirements.txt (line 2))\n  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m27.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting scikit-image==0.21.0 (from -r requirements.txt (line 3))\n  Downloading scikit_image-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting opencv-python==4.7.0.72 (from -r requirements.txt (line 4))\n  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting pillow==9.4.0 (from -r requirements.txt (line 5))\n  Downloading Pillow-9.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\nCollecting diffusers==0.25.1 (from -r requirements.txt (line 6))\n  Downloading diffusers-0.25.1-py3-none-any.whl.metadata (19 kB)\nCollecting transformers==4.41.1 (from -r requirements.txt (line 7))\n  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.3.0)\nCollecting matplotlib==3.7.4 (from -r requirements.txt (line 9))\n  Downloading matplotlib-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting tqdm==4.64.1 (from -r requirements.txt (line 10))\n  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting config==0.5.1 (from -r requirements.txt (line 11))\n  Downloading config-0.5.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting einops==0.7.0 (from -r requirements.txt (line 12))\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting onnxruntime==1.16.2 (from -r requirements.txt (line 13))\n  Downloading onnxruntime-1.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting basicsr (from -r requirements.txt (line 14))\n  Downloading basicsr-1.4.2.tar.gz (172 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting av (from -r requirements.txt (line 15))\n  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\nCollecting fvcore (from -r requirements.txt (line 16))\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.1.1)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.3.0)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (2.0.8)\nCollecting huggingface_hub==0.25.2 (from -r requirements.txt (line 20))\n  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.14.0)\nRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (3.4.2)\nRequirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (2025.1.10)\nRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (1.8.0)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (24.2)\nRequirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->-r requirements.txt (line 3)) (0.4)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 6)) (8.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 6)) (3.18.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 6)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 6)) (0.5.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.1->-r requirements.txt (line 7)) (6.0.2)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.41.1->-r requirements.txt (line 7))\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.4->-r requirements.txt (line 9)) (2.9.0.post0)\nCollecting coloredlogs (from onnxruntime==1.16.2->-r requirements.txt (line 13))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.16.2->-r requirements.txt (line 13)) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.16.2->-r requirements.txt (line 13)) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.16.2->-r requirements.txt (line 13)) (1.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.2->-r requirements.txt (line 20)) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.25.2->-r requirements.txt (line 20)) (4.13.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 8)) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 8)) (2.5.1+cu124)\nCollecting addict (from basicsr->-r requirements.txt (line 14))\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from basicsr->-r requirements.txt (line 14)) (1.0.0)\nCollecting lmdb (from basicsr->-r requirements.txt (line 14))\n  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting tb-nightly (from basicsr->-r requirements.txt (line 14))\n  Downloading tb_nightly-2.20.0a20250509-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from basicsr->-r requirements.txt (line 14)) (0.20.1+cu124)\nCollecting yapf (from basicsr->-r requirements.txt (line 14))\n  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting yacs>=0.1.6 (from fvcore->-r requirements.txt (line 16))\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->-r requirements.txt (line 16)) (2.5.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->-r requirements.txt (line 16)) (0.9.0)\nCollecting iopath>=0.1.7 (from fvcore->-r requirements.txt (line 16))\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 18)) (4.9.3)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 21))\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio->-r requirements.txt (line 21))\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.10.0 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio->-r requirements.txt (line 21))\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (0.28.1)\nINFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.27.1-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.9.1 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.9.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.9.0 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.8.0 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.25.1-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\nINFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n  Downloading gradio-5.24.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.23.2-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.23.0-py3-none-any.whl.metadata (16 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.7.2 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.18.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.7.1 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.17.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.16.2-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.16.1-py3-none-any.whl.metadata (16 kB)\nCollecting gradio-client==1.7.0 (from gradio->-r requirements.txt (line 21))\n  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting gradio (from -r requirements.txt (line 21))\n  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.1.6)\nCollecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 21))\n  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.10.15)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (2.2.3)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (2.11.3)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 21))\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting ruff>=0.9.3 (from gradio->-r requirements.txt (line 21))\n  Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 21))\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 21))\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 21))\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 21))\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (0.15.1)\nCollecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 21))\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio->-r requirements.txt (line 21)) (14.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 21)) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 21)) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (0.14.0)\nCollecting portalocker (from iopath>=0.1.7->fvcore->-r requirements.txt (line 16))\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 21)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 21)) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 21)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 21)) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 21)) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.4->-r requirements.txt (line 9)) (1.17.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 8))\n  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 8)) (3.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.16.2->-r requirements.txt (line 13)) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (14.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.16.2->-r requirements.txt (line 13))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.1->-r requirements.txt (line 6)) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 6)) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (1.70.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (3.7)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (75.1.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 14)) (3.1.3)\nRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->basicsr->-r requirements.txt (line 14)) (4.3.7)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (0.1.2)\nDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Pillow-9.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading matplotlib-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading config-0.5.1-py2.py3-none-any.whl (20 kB)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio-5.14.0-py3-none-any.whl (57.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\nUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\nUsing cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\nUsing cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\nUsing cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\nUsing cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\nUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m100.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tb_nightly-2.20.0a20250509-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: basicsr, fvcore, iopath\n  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=e8a21e72919b0159aaa90940e9929fc5ed176b3c0ce5ee44f87e9f60c4914d50\n  Stored in directory: /root/.cache/pip/wheels/6d/a4/b3/9f888ba88efcae6dd4bbce69832363de9c4051142674f779fa\n  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=9d964375d237d8d47f36175f1964e5398fadbe6714624023f408f7091b04fd71\n  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=3aa6bb73df98fa84d23b66526594d4c2aaf860120dcae5b593df5042447d3ced\n  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\nSuccessfully built basicsr fvcore iopath\nInstalling collected packages: lmdb, config, addict, yapf, yacs, uvicorn, tqdm, tomlkit, semantic-version, ruff, python-multipart, portalocker, pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, numpy, markupsafe, humanfriendly, ffmpy, einops, av, starlette, scipy, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, huggingface_hub, coloredlogs, tokenizers, tb-nightly, scikit-image, safehttpx, onnxruntime, nvidia-cusolver-cu12, matplotlib, gradio-client, fvcore, fastapi, diffusers, transformers, gradio, basicsr\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.67.1\n    Uninstalling tqdm-4.67.1:\n      Successfully uninstalled tqdm-4.67.1\n  Attempting uninstall: pillow\n    Found existing installation: pillow 11.1.0\n    Uninstalling pillow-11.1.0:\n      Successfully uninstalled pillow-11.1.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\n  Attempting uninstall: einops\n    Found existing installation: einops 0.8.1\n    Uninstalling einops-0.8.1:\n      Successfully uninstalled einops-0.8.1\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.11.0.86\n    Uninstalling opencv-python-4.11.0.86:\n      Successfully uninstalled opencv-python-4.11.0.86\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.30.2\n    Uninstalling huggingface-hub-0.30.2:\n      Successfully uninstalled huggingface-hub-0.30.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.25.1\n    Uninstalling scikit-image-0.25.1:\n      Successfully uninstalled scikit-image-0.25.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n  Attempting uninstall: diffusers\n    Found existing installation: diffusers 0.32.2\n    Uninstalling diffusers-0.32.2:\n      Successfully uninstalled diffusers-0.32.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.4 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.4 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.4 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ndatasets 3.5.0 requires tqdm>=4.66.3, but you have tqdm 4.64.1 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\nfeaturetools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.64.1 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\nkaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\nbayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\npymc 5.20.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\nlangchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.24.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.4 which is incompatible.\ntreescope 0.1.8 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nblosc2 3.1.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed addict-2.4.0 av-14.3.0 basicsr-1.4.2 coloredlogs-15.0.1 config-0.5.1 diffusers-0.25.1 einops-0.7.0 fastapi-0.115.12 ffmpy-0.5.0 fvcore-0.1.5.post20221221 gradio-5.14.0 gradio-client-1.7.0 huggingface_hub-0.25.2 humanfriendly-10.0 iopath-0.1.10 lmdb-1.6.2 markupsafe-2.1.5 matplotlib-3.7.4 numpy-1.24.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.16.2 opencv-python-4.7.0.72 pillow-9.4.0 portalocker-3.1.1 python-multipart-0.0.20 ruff-0.11.9 safehttpx-0.1.6 scikit-image-0.21.0 scipy-1.10.1 semantic-version-2.10.0 starlette-0.46.2 tb-nightly-2.20.0a20250509 tokenizers-0.19.1 tomlkit-0.13.2 tqdm-4.64.1 transformers-4.41.1 uvicorn-0.34.2 yacs-0.1.8 yapf-0.43.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install huggingface_hub hf_transfer\n!pip install flask\n!pip install pyngrok\n!rm -rf /opt/conda/lib/python3.10/site-packages/numpy*\n!pip install numpy==1.26.4\n!pip install bitsandbytes==0.43.0 accelerate==0.30.1 peft==0.11.1 --upgrade\n!pip install torchvision==0.19.1 xformers --extra-index-url https://download.pytorch.org/whl/cu121","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:11:47.906701Z","iopub.execute_input":"2025-05-10T09:11:47.906936Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.64.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\nRequirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (2.1.5)\nCollecting pyngrok\n  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.8\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.4\n    Uninstalling numpy-1.24.4:\n      Successfully uninstalled numpy-1.24.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ndatasets 3.5.0 requires tqdm>=4.66.3, but you have tqdm 4.64.1 which is incompatible.\nfeaturetools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.64.1 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\nkaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.4 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\nCollecting bitsandbytes==0.43.0\n  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\nCollecting accelerate==0.30.1\n  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\nCollecting peft==0.11.1\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.0) (2.5.1+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (6.0.2)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (0.25.2)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (0.5.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.41.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.64.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (2025.3.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->bitsandbytes==0.43.0) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (2024.11.6)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.43.0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (2025.1.31)\nDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes, accelerate, peft\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.3.0\n    Uninstalling accelerate-1.3.0:\n      Successfully uninstalled accelerate-1.3.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed accelerate-0.30.1 bitsandbytes-0.43.0 peft-0.11.1\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\nCollecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting xformers\n  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (1.26.4)\nCollecting torch==2.4.1 (from torchvision==0.19.1)\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (9.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1->torchvision==0.19.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1->torchvision==0.19.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1->torchvision==0.19.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (9.1.0.70)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1->torchvision==0.19.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade pillow\nimport sys\nsys.path.append('/kaggle/working/content/Virtual_Vogue')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nfrom PIL import Image\nfrom src.tryon_pipeline import StableDiffusionXLInpaintPipeline as TryonPipeline\nfrom src.unet_hacked_garmnet import UNet2DConditionModel as UNet2DConditionModel_ref\nfrom src.unet_hacked_tryon import UNet2DConditionModel\nfrom transformers import (\n    CLIPImageProcessor,\n    CLIPVisionModelWithProjection,\n)\nfrom diffusers import AutoencoderKL\nfrom typing import List\nfrom util.common import open_folder\nfrom util.image import pil_to_binary_mask, save_output_image\nfrom utils_mask import get_mask_location\nfrom torchvision import transforms\nimport apply_net\nfrom preprocess.humanparsing.run_parsing import Parsing\nfrom preprocess.openpose.run_openpose import OpenPose\nfrom detectron2.data.detection_utils import convert_PIL_to_numpy,_apply_exif_orientation\nfrom torchvision.transforms.functional import to_pil_image\nfrom util.pipeline import quantize_4bit, restart_cpu_offload, torch_gc\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lowvram = False\nload_mode = \"8bit\"\nfixed_vae = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dtype = torch.float16\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_id = 'yisol/IDM-VTON'\nvae_model_id = 'madebyollin/sdxl-vae-fp16-fix'\n\ndtypeQuantize = dtype","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if(load_mode in ('4bit','8bit')):\n    dtypeQuantize = torch.float8_e4m3fn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ENABLE_CPU_OFFLOAD = lowvram\ntorch.backends.cudnn.allow_tf32 = False\ntorch.backends.cuda.allow_tf32 = False\nneed_restart_cpu_offloading = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unet = None\npipe = None\nUNet_Encoder = None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if pipe == None:\n      unet = UNet2DConditionModel.from_pretrained(\n          model_id,\n          subfolder=\"unet\",\n          torch_dtype=dtypeQuantize,\n      )\n      if load_mode == '4bit':\n          quantize_4bit(unet)\n          \n      unet.requires_grad_(False)\n      \n      image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n          model_id,\n          subfolder=\"image_encoder\",\n          torch_dtype=torch.float16,\n          )\n      if load_mode == '4bit':\n          quantize_4bit(image_encoder)\n      \n      if fixed_vae:\n          vae = AutoencoderKL.from_pretrained(vae_model_id, torch_dtype=dtype)\n      else:            \n          vae = AutoencoderKL.from_pretrained(model_id,\n                                              subfolder=\"vae\",\n                                              torch_dtype=dtype,\n          )\n\n      # \"stabilityai/stable-diffusion-xl-base-1.0\",\n      UNet_Encoder = UNet2DConditionModel_ref.from_pretrained(\n          model_id,\n          subfolder=\"unet_encoder\",\n          torch_dtype=dtypeQuantize,\n      )\n    \n      if load_mode == '4bit':\n          quantize_4bit(UNet_Encoder)\n\n      UNet_Encoder.requires_grad_(False)\n      image_encoder.requires_grad_(False)\n      vae.requires_grad_(False)\n      unet.requires_grad_(False)\n            \n      pipe_param = {\n              'pretrained_model_name_or_path': model_id,\n              'unet': unet,     \n              'torch_dtype': dtype,   \n              'vae': vae,\n              'image_encoder': image_encoder,\n              'feature_extractor': CLIPImageProcessor(),\n          }\n      \n      pipe = TryonPipeline.from_pretrained(**pipe_param).to(device)\n      pipe.unet_encoder = UNet_Encoder    \n      pipe.unet_encoder.to(pipe.unet.device)\n\n      if load_mode == '4bit':\n          if pipe.text_encoder is not None:\n              quantize_4bit(pipe.text_encoder)\n          if pipe.text_encoder_2 is not None:\n              quantize_4bit(pipe.text_encoder_2)\n          \nelse:\n      if ENABLE_CPU_OFFLOAD:\n          need_restart_cpu_offloading =True\n  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    torch_gc() \n    parsing_model = Parsing(0)\n    openpose_model = OpenPose(0)\n    openpose_model.preprocessor.body_estimation.model.to(device)\n    tensor_transfrom = transforms.Compose(\n                    [\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.5], [0.5]),\n                    ]\n            )\n    \n    if need_restart_cpu_offloading:\n        restart_cpu_offload(pipe, load_mode)\n    elif ENABLE_CPU_OFFLOAD:\n        pipe.enable_model_cpu_offload()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --id 1YTZPSg-XOr4uNVZBFRwdYaeVCutqb029\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!gdown --id 1xv6FgbK6b52EiSGLfv7SpHdkhrCBSEN0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image\n\n# Paths\nproto_file = \"pose_deploy_linevec.prototxt\"\nweights_file = \"pose_iter_440000.caffemodel\"\nimage_path = \"/kaggle/working/content/Virtual_Vogue/example/human/00034_00.jpg\"\n\n# Load model\nnet = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n\n# Load input image\nframe = cv2.imread(image_path)\nframeHeight, frameWidth = frame.shape[:2]\n\n# Prepare input\ninWidth = 368\ninHeight = 368\ninpBlob = cv2.dnn.blobFromImage(frame, 1.0/255, (inWidth, inHeight), (0,0,0), swapRB=False, crop=False)\nnet.setInput(inpBlob)\noutput = net.forward()\n\n# Define body parts\nBODY_PARTS = { \n    \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n    \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n    \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13,\n    \"REye\": 14, \"LEye\": 15, \"REar\": 16, \"LEar\": 17\n}\n\nPOSE_PAIRS = [\n    (\"Neck\", \"RShoulder\"), (\"Neck\", \"LShoulder\"),\n    (\"RShoulder\", \"RElbow\"), (\"RElbow\", \"RWrist\"),\n    (\"LShoulder\", \"LElbow\"), (\"LElbow\", \"LWrist\"),\n    (\"Neck\", \"RHip\"), (\"RHip\", \"RKnee\"), (\"RKnee\", \"RAnkle\"),\n    (\"Neck\", \"LHip\"), (\"LHip\", \"LKnee\"), (\"LKnee\", \"LAnkle\"),\n    (\"Neck\", \"Nose\"), (\"Nose\", \"REye\"), (\"REye\", \"REar\"),\n    (\"Nose\", \"LEye\"), (\"LEye\", \"LEar\")\n]\n\n# Extract keypoints\npoints = []\nthreshold = 0.1\nfor i in range(len(BODY_PARTS)):\n    probMap = output[0, i, :, :]\n    _, prob, _, point = cv2.minMaxLoc(probMap)\n\n    x = (frameWidth * point[0]) / output.shape[3]\n    y = (frameHeight * point[1]) / output.shape[2]\n\n    if prob > threshold:\n        points.append((int(x), int(y)))\n    else:\n        points.append(None)\n\n# Create a black background\nblank = np.zeros((frameHeight, frameWidth, 3), dtype=np.uint8)\n\n# Generate rainbow colors for each connection\ncolors = plt.cm.rainbow(np.linspace(0, 1, len(POSE_PAIRS)))\ncolors = (colors[:, :3] * 255).astype(np.uint8)  # Convert from 0-1 float to 0-255 int\n\n# Draw colorful skeleton\nfor idx, pair in enumerate(POSE_PAIRS):\n    partFrom = pair[0]\n    partTo = pair[1]\n\n    idFrom = BODY_PARTS[partFrom]\n    idTo = BODY_PARTS[partTo]\n\n    if points[idFrom] and points[idTo]:\n        x1, y1 = points[idFrom]\n        x2, y2 = points[idTo]\n\n        color = tuple(int(c) for c in colors[idx])  # RGB color for this link\n\n        cv2.line(blank, (x1, y1), (x2, y2), color, thickness=4, lineType=cv2.LINE_AA)\n        cv2.circle(blank, (x1, y1), 5, color, thickness=-1, lineType=cv2.LINE_AA)\n        cv2.circle(blank, (x2, y2), 5, color, thickness=-1, lineType=cv2.LINE_AA)\n\n# Convert to PIL\nblank_rgb = cv2.cvtColor(blank, cv2.COLOR_BGR2RGB)\nimageABC = Image.fromarray(blank_rgb)\n\n# Done!\nimageABC\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # To View\n# plt.imshow(cv2.cvtColor(imageABC, cv2.COLOR_BGR2RGB))\n# plt.axis('off')\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom PIL import Image\n\ngarm_image = Image.open('/kaggle/working/content/Virtual_Vogue/example/cloth/09164_00.jpg')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"garm_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"garment_des = \"a dress\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"person = Image.open('/kaggle/working/content/Virtual_Vogue/example/human/00034_00.jpg')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"person","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"garm_img= garm_image.convert(\"RGB\").resize((768,1024))\nhuman_img_orig = person.convert(\"RGB\")  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_checked = True\nis_checked_crop = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if is_checked_crop:\n    width, height = human_img_orig.size\n    target_width = int(min(width, height * (3 / 4)))\n    target_height = int(min(height, width * (4 / 3)))\n    left = (width - target_width) / 2\n    top = (height - target_height) / 2\n    right = (width + target_width) / 2\n    bottom = (height + target_height) / 2\n    cropped_img = human_img_orig.crop((left, top, right, bottom))\n    crop_size = cropped_img.size\n    human_img = cropped_img.resize((768,1024))\nelse:\n    human_img = human_img_orig.resize((768,1024))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category = \"upper_body\" #\"upper_body\", \"lower_body\", \"dresses\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if is_checked:\n    keypoints = openpose_model(human_img.resize((384,512)))\n    model_parse, _ = parsing_model(human_img.resize((384,512)))\n    mask, mask_gray = get_mask_location('hd', category, model_parse, keypoints)\n    mask = mask.resize((768,1024))\nelse:\n    mask = pil_to_binary_mask(dict['layers'][0].convert(\"RGB\").resize((768, 1024)))\n    # mask = transforms.ToTensor()(mask)\n    # mask = mask.unsqueeze(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask_gray = (1-transforms.ToTensor()(mask)) * tensor_transfrom(human_img)\nmask_gray = to_pil_image((mask_gray+1.0)/2.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask_gray","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"human_img_arg = _apply_exif_orientation(human_img.resize((384,512)))\nhuman_img_arg = convert_PIL_to_numpy(human_img_arg, format=\"BGR\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = apply_net.create_argument_parser().parse_args(('show', '/kaggle/working/content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_s1x.yaml', '/kaggle/working/content/Virtual_Vogue/ckpt/densepose/model_final_162be9.pkl', 'dp_segm', '-v', '--opts', 'MODEL.DEVICE', 'cuda'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# verbosity = getattr(args, \"verbosity\", None)\npose_img = args.func(args,human_img_arg)    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pose_img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pose_img = pose_img[:,:,::-1]    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pose_img = Image.fromarray(pose_img).resize((768,1024))\n# pose_img = pose_img.resize((768,1024))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pose_img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(pose_img)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if pipe.text_encoder is not None:        \n    pipe.text_encoder.to(device)\n\nif pipe.text_encoder_2 is not None:\n    pipe.text_encoder_2.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\ndenoise_steps = 30\nnumber_of_images = 1\nis_randomize_seed = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    # Extract the images\n    with torch.cuda.amp.autocast(dtype=dtype):\n        with torch.no_grad():\n            prompt = \"model is wearing \" + garment_des\n            negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n            with torch.inference_mode():\n                (\n                    prompt_embeds,\n                    negative_prompt_embeds,\n                    pooled_prompt_embeds,\n                    negative_pooled_prompt_embeds,\n                ) = pipe.encode_prompt(\n                    prompt,\n                    num_images_per_prompt=1,\n                    do_classifier_free_guidance=True,\n                    negative_prompt=negative_prompt,\n                )\n                                \n                prompt = \"a photo of \" + garment_des\n                negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n                if not isinstance(prompt, List):\n                    prompt = [prompt] * 1\n                if not isinstance(negative_prompt, List):\n                    negative_prompt = [negative_prompt] * 1\n                with torch.inference_mode():\n                    (\n                        prompt_embeds_c,\n                        _,\n                        _,\n                        _,\n                    ) = pipe.encode_prompt(\n                        prompt,\n                        num_images_per_prompt=1,\n                        do_classifier_free_guidance=False,\n                        negative_prompt=negative_prompt,\n                    )\n\n                pose_img =  tensor_transfrom(pose_img).unsqueeze(0).to(device,dtype)\n                garm_tensor =  tensor_transfrom(garm_img).unsqueeze(0).to(device,dtype)\n                results = []\n                current_seed = seed\n                for i in range(number_of_images):  \n                    if is_randomize_seed:\n                        current_seed = torch.randint(0, 2**32, size=(1,)).item()                        \n                    generator = torch.Generator(device).manual_seed(current_seed) if seed != -1 else None                     \n                    current_seed = current_seed + i\n\n                    images = pipe(\n                        prompt_embeds=prompt_embeds.to(device,dtype),\n                        negative_prompt_embeds=negative_prompt_embeds.to(device,dtype),\n                        pooled_prompt_embeds=pooled_prompt_embeds.to(device,dtype),\n                        negative_pooled_prompt_embeds=negative_pooled_prompt_embeds.to(device,dtype),\n                        num_inference_steps=denoise_steps,\n                        generator=generator,\n                        strength = 1.0,\n                        pose_img = pose_img.to(device,dtype),\n                        text_embeds_cloth=prompt_embeds_c.to(device,dtype),\n                        cloth = garm_tensor.to(device,dtype),\n                        mask_image=mask,\n                        image=human_img, \n                        height=1024,\n                        width=768,\n                        ip_adapter_image = garm_img.resize((768,1024)),\n                        guidance_scale=2.0,\n                        dtype=dtype,\n                        device=device,\n                    )[0]\n                    if is_checked_crop:\n                        out_img = images[0].resize(crop_size)        \n                        human_img_orig.paste(out_img, (int(left), int(top)))   \n                        img_path = save_output_image(human_img_orig, base_path=\"outputs\", base_filename='img', seed=current_seed)\n                        results.append(img_path)\n                    else:\n                        img_path = save_output_image(images[0], base_path=\"outputs\", base_filename='img')\n                        results.append(img_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def try_on(garm_img, human_img, garment_des, category, is_checked, is_checked_crop, \n           denoise_steps, seed, number_of_images, is_randomize_seed):\n    global pipe, parsing_model, openpose_model\n    \n    garm_img = garm_img.convert(\"RGB\").resize((768,1024))\n    human_img_orig = human_img.convert(\"RGB\")    \n    \n    if is_checked_crop:\n        width, height = human_img_orig.size\n        target_width = int(min(width, height * (3 / 4)))\n        target_height = int(min(height, width * (4 / 3)))\n        left = (width - target_width) / 2\n        top = (height - target_height) / 2\n        right = (width + target_width) / 2\n        bottom = (height + target_height) / 2\n        cropped_img = human_img_orig.crop((left, top, right, bottom))\n        crop_size = cropped_img.size\n        human_img = cropped_img.resize((768,1024))\n    else:\n        human_img = human_img_orig.resize((768,1024))\n\n    # if is_checked:\n    keypoints = openpose_model(human_img.resize((384,512)))\n    model_parse, _ = parsing_model(human_img.resize((384,512)))\n    mask, mask_gray = get_mask_location('hd', category, model_parse, keypoints)\n    mask = mask.resize((768,1024))\n    # else:\n    #     mask = pil_to_binary_mask(dict['layers'][0].convert(\"RGB\").resize((768, 1024)))\n    #     # mask = transforms.ToTensor()(mask)\n    #     # mask = mask.unsqueeze(0)\n    \n    mask_gray = (1-transforms.ToTensor()(mask)) * tensor_transfrom(human_img)\n    mask_gray = to_pil_image((mask_gray+1.0)/2.0)\n\n    human_img_arg = _apply_exif_orientation(human_img.resize((384,512)))\n    human_img_arg = convert_PIL_to_numpy(human_img_arg, format=\"BGR\")\n\n    args = apply_net.create_argument_parser().parse_args(('show', '/kaggle/working/content/Virtual_Vogue/configs/densepose_rcnn_R_50_FPN_s1x.yaml', '/kaggle/working/content/Virtual_Vogue/ckpt/densepose/model_final_162be9.pkl', 'dp_segm', '-v', '--opts', 'MODEL.DEVICE', 'cuda'))\n    # verbosity = getattr(args, \"verbosity\", None)\n    pose_img = args.func(args,human_img_arg)    \n    pose_img = pose_img[:,:,::-1]    \n    pose_img = Image.fromarray(pose_img).resize((768,1024))\n    \n    if pipe.text_encoder is not None:        \n        pipe.text_encoder.to(device)\n\n    if pipe.text_encoder_2 is not None:\n        pipe.text_encoder_2.to(device)\n\n    with torch.no_grad():\n        # Extract the images\n        with torch.cuda.amp.autocast(dtype=dtype):\n            with torch.no_grad():\n                prompt = \"model is wearing \" + garment_des\n                negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n                with torch.inference_mode():\n                    (\n                        prompt_embeds,\n                        negative_prompt_embeds,\n                        pooled_prompt_embeds,\n                        negative_pooled_prompt_embeds,\n                    ) = pipe.encode_prompt(\n                        prompt,\n                        num_images_per_prompt=1,\n                        do_classifier_free_guidance=True,\n                        negative_prompt=negative_prompt,\n                    )\n                                    \n                    prompt = \"a photo of \" + garment_des\n                    negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n                    if not isinstance(prompt, List):\n                        prompt = [prompt] * 1\n                    if not isinstance(negative_prompt, List):\n                        negative_prompt = [negative_prompt] * 1\n                    with torch.inference_mode():\n                        (\n                            prompt_embeds_c,\n                            _,\n                            _,\n                            _,\n                        ) = pipe.encode_prompt(\n                            prompt,\n                            num_images_per_prompt=1,\n                            do_classifier_free_guidance=False,\n                            negative_prompt=negative_prompt,\n                        )\n\n                    pose_img =  tensor_transfrom(pose_img).unsqueeze(0).to(device,dtype)\n                    garm_tensor =  tensor_transfrom(garm_img).unsqueeze(0).to(device,dtype)\n                    results = []\n                    current_seed = seed\n                    for i in range(number_of_images):  \n                        if is_randomize_seed:\n                            current_seed = torch.randint(0, 2**32, size=(1,)).item()                        \n                        generator = torch.Generator(device).manual_seed(current_seed) if seed != -1 else None                     \n                        current_seed = current_seed + i\n\n                        images = pipe(\n                            prompt_embeds=prompt_embeds.to(device,dtype),\n                            negative_prompt_embeds=negative_prompt_embeds.to(device,dtype),\n                            pooled_prompt_embeds=pooled_prompt_embeds.to(device,dtype),\n                            negative_pooled_prompt_embeds=negative_pooled_prompt_embeds.to(device,dtype),\n                            num_inference_steps=denoise_steps,\n                            generator=generator,\n                            strength = 1.0,\n                            pose_img = pose_img.to(device,dtype),\n                            text_embeds_cloth=prompt_embeds_c.to(device,dtype),\n                            cloth = garm_tensor.to(device,dtype),\n                            mask_image=mask,\n                            image=human_img, \n                            height=1024,\n                            width=768,\n                            ip_adapter_image = garm_img.resize((768,1024)),\n                            guidance_scale=2.0,\n                            dtype=dtype,\n                            device=device,\n                        )[0]\n                        if is_checked_crop:\n                            out_img = images[0].resize(crop_size)        \n                            human_img_orig.paste(out_img, (int(left), int(top)))   \n                            img_path = save_output_image(human_img_orig, base_path=\"outputs\", base_filename='img', seed=current_seed)\n                            results.append(img_path)\n                        else:\n                            img_path = save_output_image(images[0], base_path=\"outputs\", base_filename='img')\n                            results.append(img_path)\n                    return results, mask_gray\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results, mask_gray = try_on(\n    garm_img=garm_img,\n    human_img=human_img,\n    garment_des=garment_des,\n    category=category,\n    is_checked=False,\n    is_checked_crop=False,\n    denoise_steps=50,\n    seed=seed,\n    number_of_images=number_of_images,\n    is_randomize_seed=is_randomize_seed\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install flask-cors","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport threading\n\nfrom flask import Flask\nfrom pyngrok import ngrok, conf\nfrom flask_cors import CORS\nfrom flask import request, jsonify\nimport io\nimport base64\n\napp = Flask(__name__)\nCORS(app)\nconf.get_default().auth_token = \"2tq97lr2ZzRlbMhPKotNOYm012p_7kY3ApxfoinxA888RZBh2\"\n\nos.environ[\"FLASK_ENV\"] = \"development\"\n\nPORT = 8002\npublic_url = ngrok.connect(PORT).public_url\nprint(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 7860))\n\napp.config[\"BASE_URL\"] = public_url\n\n@app.route(\"/\")\ndef index():\n    return \"CORS ON\"\n@app.route('/try_on', methods=['POST'])\ndef try_on_endpoint():\n    try:\n        # Get input data\n        garm_img = Image.open(io.BytesIO(request.files['garment_image'].read()))\n        human_img = Image.open(io.BytesIO(request.files['human_image'].read()))\n        \n        params = request.form.to_dict()\n        \n        # Process parameters\n        garment_des = params.get('garment_description', '')\n        category = params.get('category', 'upper_body')\n        is_checked = params.get('is_checked', 'true').lower() == 'true'\n        is_checked_crop = params.get('is_checked_crop', 'true').lower() == 'true'\n        denoise_steps = int(params.get('denoise_steps', 20))\n        seed = int(params.get('seed', -1))\n        number_of_images = int(params.get('number_of_images', 1))\n        is_randomize_seed = params.get('is_randomize_seed', 'false').lower() == 'true'\n\n        # Run inference\n        results, mask_gray = try_on(\n            garm_img=garm_img,\n            human_img=human_img,\n            garment_des=garment_des,\n            category=category,\n            is_checked=True,\n            is_checked_crop=True,\n            denoise_steps=denoise_steps,\n            seed=seed,\n            number_of_images=number_of_images,\n            is_randomize_seed=is_randomize_seed\n        )\n\n        # Convert results to base64 for API response\n        encoded_images = []\n        for img_path in results:\n            with open(img_path, \"rb\") as image_file:\n                encoded_images.append(base64.b64encode(image_file.read()).decode('utf-8'))\n        \n        return jsonify({\n            \"status\": \"success\",\n            \"images\": encoded_images,\n            \"mask\": base64.b64encode(mask_gray.tobytes()).decode('utf-8')\n        })\n        \n    except Exception as e:\n        return jsonify({\"status\": \"error\", \"message\": str(e)})\n        \n\n# Start Flask server with explicit port configuration\nthreading.Thread(\n    target=app.run,\n    kwargs={\n        \"host\": \"0.0.0.0\",\n        \"port\": PORT,\n        \"use_reloader\": False,\n        \"debug\": True\n    }\n).start()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep the notebook running forever\nimport time\n\nwhile True:\n    time.sleep(60)  # Sleep for 60 seconds\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}